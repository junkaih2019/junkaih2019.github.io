{"title":"1 什么是自然语言处理（NLP）","uid":"18cd34895fd3ec17b3af53a59599684c","slug":"nlp1","date":"2021-05-05T09:19:36.000Z","updated":"2021-05-05T14:45:33.865Z","comments":true,"path":"api/articles/nlp1.json","cover":"https://th.bing.com/th/id/Rfe0d66ca9986b01e4754156a726664d9?rik=JmplG%2beHM6QiDA&riu=http%3a%2f%2fstatic.jwcyber.com%2fwp-content%2fuploads%2f2017%2f10%2f1459090493139970.jpg&ehk=4IdnknKz6SDek%2fYNbzEpRxuY7wXlHilZ8KVNjkUXkhc%3d&risl=&pid=ImgRaw","content":"<p>此系列文章是对哥大NLP课程的笔记。<br>原课程网站为：<a href=\"http://www.cs.columbia.edu/~mcollins/cs4705-spring2020/\">COMS W4705 Natural Language Processing</a></p>\n<h2 id=\"什么是自然语言处理（NLP）\"><a href=\"#什么是自然语言处理（NLP）\" class=\"headerlink\" title=\"什么是自然语言处理（NLP）\"></a>什么是自然语言处理（NLP）</h2><ol>\n<li>从输入输出角度看，计算机处理语言有两个方面：</li>\n</ol>\n<ul>\n<li><p>分析语言（NLU)，试图将语言当做输入，去理解语言的含义</p>\n</li>\n<li><p>整合语言（NLG），试图输出自然语言</p>\n</li>\n</ul>\n<img src=\"..\\nlp1\\image-20210401213017450.png\" alt=\"image-20210401213017450\" style=\"zoom: 80%;\" />\n\n<ol start=\"2\">\n<li>从应用来看</li>\n</ol>\n<ul>\n<li><p>机器翻译（Machine Translation)<br>之后会介绍建立一个模型的关键步骤</p>\n</li>\n<li><p>信息抽取（Information Extraction)<br>将一大段的信息<strong>理解</strong>（NLU），将其压缩成类似于数据库中表的结构。<br>进一步有利于对信息进行：</p>\n</li>\n</ul>\n<ul>\n<li><p>复杂查找:<br>例如从一个招聘网站查找“薪水至少5000并在深圳的职位”，先将网页中的职位信息转换为数据库结构，再在数据库中查找会方便的多</p>\n</li>\n<li><p>数据统计:<br>例如要统计几年来会计职位数的变化，同理会更方便</p>\n<img src=\"..\\nlp1\\image-20210401213931986.png\" alt=\"image-20210401213931986\" style=\"zoom:67%;\" /></li>\n</ul>\n<ul>\n<li>文本摘要 (Text Summarization)<br>压缩一个或多个文件中的信息，生成一篇摘要，覆盖多个要点</li>\n</ul>\n<img src=\"..\\nlp1\\image-20210401215155725.png\" alt=\"image-20210401215155725\" style=\"zoom:67%;\" />\n\n\n\n<ul>\n<li>对话系统(Dialogue System)<br>其基本问题在于，让机器用自然语言与用户进行交流。一般包含两个过程，一是NLU的过程，理解用户输入的自然语言；二是NLG的过程，例如将分类问题的结果输出为自然语言。</li>\n</ul>\n<img src=\"..\\nlp1\\image-20210401215609483.png\" alt=\"image-20210401215609483\" style=\"zoom:67%;\" />\n\n<p>基于这些应用，一些NLP的基本问题：</p>\n<ul>\n<li>标记（Tagging)<br>简单来说，标记是将一串自然语言序列映射到一串标记序列。例1是将句子中的单词映射到不同的词性，例二是找出句子中存在的实体并标注。<img src=\"..\\nlp1\\image-20210402074448890.png\" alt=\"image-20210402074448890\" style=\"zoom:67%;\" /></li>\n<li>句法分析（Parsing)<br>输入一个句子，分析其每个词起到的语法结构，输出一课语法树。这棵语法树描述了这个句子的语法结构，有助于我们理解这个句子。<img src=\"..\\nlp1\\image-20210402202624575.png\" alt=\"image-20210402202624575\" style=\"zoom:67%;\" /></li>\n</ul>\n<h2 id=\"为什么NLP困难\"><a href=\"#为什么NLP困难\" class=\"headerlink\" title=\"为什么NLP困难\"></a>为什么NLP困难</h2><p>一些关键性难题：</p>\n<ul>\n<li>语义模糊性<br>对于同一句话，我们可以从不同角度去理解，得到截然不同的意思，例如<br>:::danger</li>\n</ul>\n<ol>\n<li>电脑像你妈了解你一样了解你</li>\n<li>电脑了解到你像你妈</li>\n<li>电脑和了解你妈一样了解你<br>::: <img src=\"..\\nlp1\\image-20210402203416112.png\" alt=\"image-20210402203416112\" style=\"zoom:67%;\" /></li>\n</ol>\n<p>  这种模糊性还体现在多种层面上，</p>\n<p>  <strong>语音层面</strong>上，例如：<br>  <img src=\"..\\nlp1\\image-20210402203751968.png\" alt=\"image-20210402203751968\" style=\"zoom:67%;\" /></p>\n<p>  <strong>语法层面</strong>上，例如：<br>  选择不同的语法结构，句子会出现不同的解释<br>  <img src=\"..\\nlp1\\image-20210402204127377.png\" alt=\"image-20210402204127377\" style=\"zoom:67%;\" /></p>\n<p>  <strong>语义层面</strong>上，例如：<br>  同一个词语，对应着多个不同的意思<br>  <img src=\"..\\nlp1\\image-20210402204454237.png\" alt=\"image-20210402204454237\" style=\"zoom:67%;\" /></p>\n<p>  <strong>论述指代</strong>上，例如：<br>  第二局中的“she”即可以指代Alice,也可以指代your mother.<br>  <img src=\"..\\nlp1\\image-20210402204810938.png\" alt=\"image-20210402204810938\" style=\"zoom:67%;\" /></p>\n<h2 id=\"课程内容是关于什么的\"><a href=\"#课程内容是关于什么的\" class=\"headerlink\" title=\"课程内容是关于什么的\"></a>课程内容是关于什么的</h2><ol>\n<li><strong>NLP子问题：</strong></li>\n</ol>\n<ul>\n<li>词类标记（part-of-speech tagging）</li>\n<li>句法分析（parsing）</li>\n<li>词义消歧（word-sense disambiguation）</li>\n</ul>\n<ol start=\"2\">\n<li><strong>机器学习技术：</strong></li>\n</ol>\n<ul>\n<li>概率上下文无关法PCFGs（probabilistic context-free grammers）</li>\n<li>隐马尔可夫模型（hidden markov models）</li>\n<li>评估/平滑方法（estimation/smoothing techniques）</li>\n<li>EM算法（the EM algorithm）</li>\n<li>对数线性模型(log-linear models）</li>\n</ul>\n<ol start=\"3\">\n<li><strong>应用</strong></li>\n</ol>\n<ul>\n<li>信息抽取（information extraction）</li>\n<li>机器翻译（machine learning）</li>\n<li>自然语言界面（natural language interfaces）</li>\n</ul>\n","feature":true,"pinned":true,"text":"此系列文章是对哥大NLP课程的笔记。原课程网站为：COMS W4705 Natural Language Processing 什么是自然语言处理（NLP） 从输入输出角度看，计算机处理语言有两个方面： 分析语言（NLU)，试图将语言当做输入，去理解语言的含义 整合语言（NLG）...","link":"","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[{"name":"NLP","slug":"NLP","count":1,"path":"api/categories/NLP.json"}],"tags":[{"name":"NLP","slug":"NLP","count":1,"path":"api/tags/NLP.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88NLP%EF%BC%89\"><span class=\"toc-text\">什么是自然语言处理（NLP）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%BA%E4%BB%80%E4%B9%88NLP%E5%9B%B0%E9%9A%BE\"><span class=\"toc-text\">为什么NLP困难</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%AF%BE%E7%A8%8B%E5%86%85%E5%AE%B9%E6%98%AF%E5%85%B3%E4%BA%8E%E4%BB%80%E4%B9%88%E7%9A%84\"><span class=\"toc-text\">课程内容是关于什么的</span></a></li></ol>","author":{"name":"JunKai","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"Keep looking, don't settle.","socials":{}},"mapped":true,"prev_post":{"title":"测试图片","uid":"5bb0bcbae3ac7b628010077fb81dc2a2","slug":"test-pic","date":"2021-05-05T11:48:44.000Z","updated":"2021-05-05T14:56:11.651Z","comments":true,"path":"api/articles/test-pic.json","cover":"https://images6.alphacoders.com/114/1145091.png","text":"复制图片 直接拖入 ","link":"","photos":[],"count_time":{"symbolsCount":10,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"JunKai","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"Keep looking, don't settle.","socials":{}},"feature":true,"pinned":true},"next_post":{"title":"article","uid":"9f603f4d8f055ec057decaa8865d8462","slug":"article-1","date":"2021-04-16T10:16:23.000Z","updated":"2021-05-05T14:54:12.616Z","comments":true,"path":"api/articles/article-1.json","cover":"https://images2.alphacoders.com/110/1105447.jpg","text":"","link":"","photos":[],"count_time":{"symbolsCount":0,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"JunKai","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"Keep looking, don't settle.","socials":{}}}}